<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml"
	  xmlns:pref="http://www.w3.org/2002/Math/preference"
      pref:renderer="css">

<head>
<script language="JavaScript1.8" type="text/javascript"><!--
	pageModDate = "28 February 2013 00:58 PST";
	// copyright 1997--2013 by P.B. Stark, statistics.berkeley.edu/~stark.
    // All rights reserved.
// -->
</script>

<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js"></script>
<script type="text/javascript" src="../../Java/Jquery/Current/jquery.bullseye-1.0.min.js"></script>

<script type="text/javascript" src="http://d3js.org/d3.v2.js"></script>

<script type="text/javascript" src="http://code.jquery.com/ui/1.9.2/jquery-ui.js"></script>
<link href="http://code.jquery.com/ui/1.9.2/themes/base/jquery-ui.css" rel="stylesheet" type="text/css" />

<script type="text/javascript" src="../../Java/sticigui.js"></script>
<link href="../../Java/CSS/sticigui.css" rel="stylesheet" type="text/css" />
<link href="../../SticiGui/Graphics/sticiGuiDefault.css" rel="stylesheet" type="text/css" />

<script language="JavaScript1.8" type="text/javascript" src="../../Java/irGrade.js"></script>

<script language="JavaScript1.8" type="text/javascript"><!--
    var cNum = "estimation";
    writeChapterHead('SeEd',cNum);
// -->
</script>
</head>

<body >
<script language="JavaScript1.8" type="text/javascript"><!--
    writeChapterNav('..');
    writeChapterTitle();
// -->
</script>

<form method="post">

<h1>
    Estimating Parameters from Simple Random Samples
</h1>

<p>
    In
<script language="JavaScript1.8" type="text/javascript"><!--
    document.writeln(citeLinkChapter('sampling') + ', ');
// -->
</script>
    we studied ways of collecting data about
    subsets of a <a class="glossRef" href="gloss.htm#population">population</a> to estimate
    <a class="glossRef" href="gloss.htm#parameter">parameters</a> of the population.
    That chapter asserted that the error in estimating a
    <a class="glossRef" href="gloss.htm#parameter">parameter</a>
    from a <a class="glossRef" href="gloss.htm#statistic">statistic</a> computed from a
    <a class="glossRef" href="gloss.htm#probability_sample">probability sample</a> can be quantified,
    while the error in estimating a parameter from other kinds of samples generally
    cannot be determined.
    This chapter studies sampling quantitatively, focusing on the error estimating a parameter
    using a statistic computed from a
    <a class="glossRef" href="gloss.htm#simple_random_sample">simple random sample</a>:
    a sample of size <span class="math">n</span> drawn from a population of
    <span class="math">N</span> units in such a way that
    each of the <span class="math"><sub>N</sub>C<sub>n</sub></span> such subsets is equally likely
    to result.
    We assume that the <a class="glossRef" href="gloss.htm#frame">frame</a> is identical to the
    population.
    After introducing measures that summarize the accuracy of estimates, we use results
    from
<script language="JavaScript1.8" type="text/javascript"><!--
    document.writeln(citeLinkChapter('counting') + ', ' +
                     citeLinkChapter('probabilityPhilosophy') + ', ' +
                     citeLinkChapter('sets') + ', ' +
                     citeLinkChapter('randomVariables') + ', ' +
                     citeLinkChapter('expectation') + ', and ' +
                     citeLinkChapter('standardError') + ', ' );
// -->
</script>
    to calculate various measures of the
    error of estimating the population mean or population percentage of a box of
    numbered tickets using the sample mean or sample percentage of a simple random sample.
    The error summaries are expressed in terms of the mean and SD of the numbers
    on the tickets in the box, along with the sample size <span class="math">n</span> and the population
    size <span class="math">N</span>.
    Results similar to those in this chapter exist for other probability sampling designs
    (like those described in the previous chapter), but this text discusses only
    simple random sampling, and random sampling with replacement.
    For more details and references, see <a href="references.htm#kish">Kish (1965)</a>.
</p>

<h3>
   <a id="estimator_error"></a>
   Quantifying the Error of Estimators
</h3>

<p>
    An <a class="glossRef" href="gloss.htm#estimator">estimator</a>
    is an assignment of a number (the estimate of the parameter) to each
    possible random sample of size <span class="math">n</span> from the population.
    For example, the <a class="glossRef" href="gloss.htm#sample_mean">sample mean</a>
    assigns to each sample of size <span class="math">n</span> the average of the
    <span class="math">n</span> values in the sample.
    The rule that assigns values to samples is called the <span class="termOfArt">estimator</span>,
    and the value that is assigned to any particular random sample is the
    <span class="termOfArt">estimate</span>.
    An estimator is a special case of a <span class="termOfArt">statistic</span>,
    a number computed from a sample.
</p>

<p>
    Because the value of the estimator depends on the sample, the estimator is a
    <a class="glossRef" href="gloss.htm#random_variable">random variable</a>, and the estimate
    typically will not equal the value of the population parameter.
    We need to understand how the value of the estimator varies with different
    possible samples, to be able to say how close or far from the parameter the
    estimator is likely to be.
    We shall use our characterization of random variables in terms of their
    <a class="glossRef" href="gloss.htm#expectation">expected value</a> and
    <a class="glossRef" href="gloss.htm#chance_variation">chance variability or sampling error</a>
    to study how estimators behave.
</p>


<h3>
    <a id="bias"></a>
    Bias
</h3>

<p>
    We can write the value the <a class="glossRef" href="gloss.htm#estimator">estimator</a>
    takes for a particular random sample as the sum of three terms: the
    <a class="glossRef" href="gloss.htm#parameter">parameter</a> we seek to estimate, systematic
    <a class="glossRef" href="gloss.htm#bias">bias</a>, and
    <a class="glossRef" href="gloss.htm#chance_variability">chance variability</a>:
</p>

<p class="math">
   <a class="glossRef" href="gloss.htm#estimator">estimator</a> =
   <a class="glossRef" href="gloss.htm#parameter">parameter</a> +
   <a class="glossRef" href="gloss.htm#bias">bias</a> +
   <a class="glossRef" href="gloss.htm#chance_variability">chance variability</a>.
</p>

<p>
    The <a class="glossRef" href="gloss.htm#chance_variability">chance variability</a> (also called
    <a class="glossRef" href="gloss.htm#sampling_error">sampling error</a> in this context)
    reflects the luck of the draw&mdash;which particular
    <a class="glossRef" href="gloss.htm#unit">units</a> happened to be in the sample.
    The <a class="glossRef" href="gloss.htm#bias">bias</a> is a systematic
    difference between the value the
    <a class="glossRef" href="gloss.htm#estimator">estimator</a> takes, and the value of the
    <a class="glossRef" href="gloss.htm#parameter">parameter</a>&mdash;a tendency for the
    <a class="glossRef" href="gloss.htm#estimator">estimator</a> to be too high or too
    low on the average.
    The bias is defined to be
</p>

<p class="math">
    <a class="glossRef" href="gloss.htm#bias">bias</a> =
    <a class="glossRef" href="gloss.htm#expectation">E</a>(<a class="glossRef" href="gloss.htm#estimator">estimator</a>)
    &minus;
    <a class="glossRef" href="gloss.htm#parameter">parameter</a>.
</p>

<p>
    Equivalently,
</p>

<p class="math">
    <a class="glossRef" href="gloss.htm#expectation">E</a>(estimator) =
    <a class="glossRef" href="gloss.htm#parameter">parameter</a> +
        <a class="glossRef" href="gloss.htm#bias">bias</a>.
</p>

<p>
    The bias is the difference between the
    expected value of the estimator
    and the true value of the parameter.
    If the bias of an estimator of a parameter is zero, the
    estimator is said to be <span class="termOfArt">unbiased</span>: Its expected value equals
    the value of the parameter it estimates.
    Otherwise, the estimator is said to be <span class="termOfArt">biased</span>.
</p>

<p>
    Because the expected value
    of the difference between the estimator and the
    parameter is the bias, the expressions above imply that the
    expected value of the chance variability is zero:
</p>

<p class="math">
    E(chance variability)&nbsp;=&nbsp;0.
</p>

<p>
    The average of the chance variability
    across all <span class="math"><sub>N</sub>C<sub>n</sub></span> samples of size
    <span class="math">n</span>
    is zero: In the long run in repeated sampling, the chance variability tends to
    average out.
</p>

<h3>
    <a id="SE"></a>
    Standard Error
</h3>

<p>
    The typical &quot;size&quot; of the
    <a class="glossRef" href="gloss.htm#chance_variability">chance variability</a>
    is the <a class="glossRef" href="gloss.htm#se">standard error (SE)</a> of the
    <a class="glossRef" href="gloss.htm#estimator">estimator</a>&mdash;the SE of the
    estimator is
    the square-root of the expected value
    of the square of the chance variability:
</p>

<p class="math">
    <a class="glossRef" href="gloss.htm#se">SE</a>(estimator) =
    <big>(</big> <a class="glossRef" href="gloss.htm#expectation">E</a><big>(</big>estimator &minus;
    <a class="glossRef" href="gloss.htm#expectation">E</a>(estimator)<big>)</big><sup>2</sup>
    <big>)</big><sup>&frac12;</sup>
</p>

<p class="math">
    = <big>(</big><a class="glossRef" href="gloss.htm#expectation">E</a>(
    (<a class="glossRef" href="gloss.htm#chance_variability">chance variability</a>
    of estimator)<sup>2</sup>)
    <big>)</big><sup>&frac12;</sup>.
</p>

<h3>
    <a id="MSE"></a>
    Mean Squared Error
</h3>

<div class="indent">
<p class="inline">
    In most problems, there is no estimator that is guaranteed to give the right answer,
    because the value of
    the estimator typically depends on the sample.
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'There are trivial exceptions.  For example, suppose we seek to estimate ' +
           'the population mean using the sample mean, and every unit has the same value ' +
           'of the variable.  Then the sample mean is always the same, and always ' +
           'equals the population mean.  If the sample size equals the population size, ' +
           'the sample mean will always equal the population mean. Similarly, suppose ' +
           'we use an estimator that is just a constant: the same value regardless ' +
           'of the sample.  If that value happens to equal the value of the ' +
           'population parameter, the estimator will always have zero error.  ' +
           'Such examples are not common.';
    writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
    The error is the difference between the estimate (the value of the estimator for a
    particular sample), and the true value of the parameter.
    That difference is the bias plus the chance variability.
    The <a class="glossRef" href="gloss.htm#bias">bias</a> is the
    long-run average difference between the parameter and the estimate if we
    repeatedly drew random samples of size <span class="math">n</span>,
    calculated the value of the estimator for the sample, and subtracted
    the parameter from the estimate.
    The <a class="glossRef" href="gloss.htm#se">standard error</a>
    measures the long-run average spread of the
    estimated values in the same hypothetical scenario.
</p>
</div>

<p>
    Both bias and standard error contribute to the average size of the error
    of an estimator.
    If the bias is large, on average the estimator
    overshoots or undershoots the truth by a large amount.
    If the SE is large, the estimator typically is far from the truth,
    even if its average is close to the truth.
    A common measure of the overall error of an estimator is its
    <a class="glossRef" href="gloss.htm#mse">mean squared error (MSE)</a>:
</p>

<p class="math">
    <a class="glossRef" href="gloss.htm#mse">MSE</a>(estimator) =
    E<big>(</big>
    (estimator &minus; parameter)<sup>2</sup> <big>)</big>
</p>

<div class="indent">
<p class="inline">
    The <a class="glossRef" href="gloss.htm#mse">mean-squared error</a> is
    the expected value of the square of the error, the
    difference between the estimator and the true value of the parameter.
    The <a class="glossRef" href="gloss.htm#mse">mean-squared error</a>
    in fact can be written in terms of the bias and SE:
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'The <a class="glossRef" href="gloss.htm#mse">MSE</a> of an ' +
       '<a class="glossRef" href="gloss.htm#estimator">estimator</a> X of a ' +
       '<a class="glossRef" href="gloss.htm#parameter">parameter</a> ' +
       '<span class="math">t</span> is</p><p class="math">' +
       'E((X&minus;t)<sup>2</sup>) = E((X&minus;E(X) + E(X)&minus;t)<sup>2</sup>)</p>' +
       '<p class="math">= E((X&minus;E(X))<sup>2</sup> + 2(X&minus;E(X))(E(X)&minus;t) ' +
       ' + (E(X)&minus;t)<sup>2</sup>)</p><p class="math">' +
       '= E((X&minus;E(X))<sup>2</sup>) + 2E((X&minus;E(X)))(E(X)&minus;t) ' +
       '+ E((E(X)&minus;t)<sup>2</sup>),</p>' +
       '<p>because <span class="math">E(X)&minus;t</span> is a constant. ' +
       'Now <span class="math">E(X&minus;E(X)) = E(X)&minus;E(X) = 0</span>, so the middle term is ' +
       '<span class="math">2&times;0&times;(E(X)&minus;t) = 0</span>, and </p>' +
       '<p class="math">E((X&minus;t)<sup>2</sup>) = E((X&minus;E(X))<sup>2</sup>)' +
       '+ E((E(X)&minus;t)<sup>2</sup>) = SE<sup>2</sup>(X) + ' +
       'bias<sup>2</sup>(X).';
    writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
</p>
</div>

<p class="math">
    <a class="glossRef" href="gloss.htm#mse">MSE</a> =
    <a class="glossRef" href="gloss.htm#bias">bias</a><sup>2</sup>
    + <a class="glossRef" href="gloss.htm#se">SE</a><sup>2</sup>.
</p>

<p>
    The <a class="glossRef" href="gloss.htm#mse">MSE</a>
    of an <a class="glossRef" href="gloss.htm#unbiased">unbiased</a> estimator
    is the square of its <a class="glossRef" href="gloss.htm#se">standard error</a>.
    The units of MSE are the squares of the units of the estimator.
    The square-root of the <a class="glossRef" href="gloss.htm#mse">MSE</a>, also called the
    <a class="glossRef" href="gloss.htm#rmse">root mean-squared error (RMSE)</a>,
    is another measure of the average error of
    an estimator; its units are the same as the units of the estimator.
    The RMSE is a reasonable summary of the average error of an estimator in repeated
    sampling.
    The RMSE is easier to interpret than MSE because its units are the same
    as the units of the estimator.
</p>

<p>
    The <a class="glossRef" href="gloss.htm#mse">MSE</a> and <a class="glossRef" href="gloss.htm#rmse">RMSE</a>
    measure the average error of an estimator.
    That is, we expect the value of an estimator to differ from the value of the parameter
    by roughly the RMSE.
    For any particular sample, however, the estimate could differ from the
    parameter by more than or by less than the RMSE.
    Typically, we cannot tell how much they differ, because we only know the
    value of the estimator, and not the true value of the parameter.
</p>

<div class="indent">
<p class="inline">
    Estimating from a sample is like shooting a rifle.
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'Which reminds me of a joke: Three statisticians go deer hunting together. ' +
           'They spot a deer close by.  The first statistician takes aim and shoots. ' +
           'His shot is a yard to the left of the deer.  The second statistician ' +
           'aims and shoots; his shot lands a yard to the right of the deer.  The third ' +
           'statistician jumps up and yells &quot;We got him!&quot;</p><p>This joke illustrates ' +
           'that bias is not all that matters: variability matters, too.';
    writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
    The parameter is the bullseye, and each shot is the value of the estimator from one
    random sample.
    A systematic tendency for all the shots to miss the bullseye in the same direction
    is <a class="glossRef" href="gloss.htm#bias">bias</a>:
    Bias is the difference between the average <em>location</em> of the shots, and
    the bullseye.
    The scatter in the shots is measured by the <a class="glossRef" href="gloss.htm#se">standard error</a>:
    the average of the distances between each shot and the average location of all
    the shots.
    The average squared <em>distance</em> between the bullseye and where the shots land
    is the <a class="glossRef" href="gloss.htm#mse">mean squared error</a>.
    For the <a class="glossRef" href="gloss.htm#mse">mean squared error</a> to be small, both the
    <a class="glossRef" href="gloss.htm#bias">bias</a> and the
    <a class="glossRef" href="gloss.htm#se">standard error</a>
    must be small.
    If the standard error is zero, but the bias is not, the estimator is like a very
    accurate rifle that has its sights mis-calibrated: All the shots hit the same
    spot, but that spot is not the bullseye.
    If the bias is zero but the standard error is not, the estimator is like an
    inaccurate rifle that is sighted in correctly: The shots are scattered around
    the bullseye, but typically miss the bullseye.
    If both the bias and the standard error are zero, so is the mean squared error,
    and the estimator is like a very accurate rifle that is sighted in correctly:
    All the shots hit the bullseye.
</p>
</div>

<div class="indent">
<p class="inline">
    There are always many estimators one could consider using to estimate a given
    parameter.
    We need some reasonable criteria for picking a sensible estimator.
    A branch of statistics called <em>Decision Theory</em> addresses the
    problem of finding an estimator that is <em>optimal</em>, given a criterion
    for comparing estimators.
    For example, many statisticians consider <a class="glossRef" href="gloss.htm#mse">MSE</a> (or RMSE)
    to be a reasonable measure of
    the accuracy of an estimator.
    In choosing among a collection of estimators
    of a particular parameter they might choose the estimator that has the smallest
    <a class="glossRef" href="gloss.htm#mse">MSE</a>.
    MSE is a common measure of accuracy, but certainly not the only one.
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'Other common measures of accuracy include the expected value of the ' +
           'absolute value of the error, the probability that a fixed-length ' +
           'interval centered at the estimator includes the parameter, <em>etc</em>. ' +
           'The application should determine an appropriate measure of accuracy, ' +
           'but <a class="glossRef" href="gloss.htm#mse">MSE</a> is the most common, because it is ' +
           'perhaps the easiest to prove theorems about.  Usually the MSE and other ' +
           'measures of accuracy depend on ' +
           'the true (unknown) value of the parameter.  When that is the case, ' +
           'it is common to minimize the maximum MSE over all possible values of the ' +
           'parameter (minimax estimation), or to minimize a weighted average of the ' +
           'MSE over some or all possible values of the parameter (Bayes estimation).';
    writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
</p>
</div>

<p>
    Other statisticians believe that it is more important for an estimator to be
    <a class="glossRef" href="gloss.htm#unbiased">unbiased</a> than to have the smallest possible
    <a class="glossRef" href="gloss.htm#mse">MSE</a>.
    Those statisticians might limit their choices to unbiased estimators.
    Within the collection of <a class="glossRef" href="gloss.htm#unbiased">unbiased</a>
    estimators, they might seek the one with the
    smallest <a class="glossRef" href="gloss.htm#se">SE</a> (and hence the smallest MSE among
    unbiased estimators, because the MSE of an unbiased estimator is equal
    to the square of its SE).
</p>

<p>
    For many <a class="glossRef" href="gloss.htm#parameter">parameters</a>, it is possible to find an
    <a class="glossRef" href="gloss.htm#unbiased">unbiased</a> estimator if the sample is drawn by
    <a class="glossRef" href="gloss.htm#simple_random_sample">simple random sampling</a>.
    However, it is common that the estimator with the smallest MSE is
    biased&mdash;an unbiased estimator cannot always have the smallest possible MSE.
    In the next section we look at two very common
    <a class="glossRef" href="gloss.htm#parameter">parameters</a>&mdash;the population
    mean and the population percentage&mdash;and at the most common estimators of those
    parameters&mdash;the <a class="glossRef" href="gloss.htm#sample_mean">sample mean</a> and the
    <a class="glossRef" href="gloss.htm#sample_percentage">sample percentage</a>.
    These estimators are <a class="glossRef" href="gloss.htm#unbiased">unbiased</a>
    when the data are a simple random sample.
</p>

<h2>
    <a id="estimation"></a>
    Estimating Means and Percentages
</h2>

<p class="video"> <iframe width="420" height="315" src="http://www.youtube.com/embed/jkWOMalw4zI?start=812&end=3145" frameborder="0" allowfullscreen></iframe>
</p>
<div class="indent">
<p class="inline">
    We saw in
<script language="JavaScript1.8" type="text/javascript"><!--
    document.writeln(citeLinkChapter('expectation') + ', ');
// -->
</script>
    that
    the <a class="glossRef" href="gloss.htm#expectation">expected value</a>
    of the <a class="glossRef" href="gloss.htm#sample_mean">sample mean</a>
    of <span class="math">n</span> random draws with or without replacement from a box is
    equal to the population mean, the average of the numbers on the tickets in the box.
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'Here is a recapitulation of the argument that the expected value of the sample ' +
           'mean is the population mean, for sampling without replacement. ' +
           'Let <span class="math">{x<sub>1</sub>, x<sub>2</sub>, &hellip; , ' +
           'x<sub>N</sub>}</span> be the ' +
           'numbers written on the tickets in the box.  The chance that any ' +
           'particular unit is in the sample was shown in the previous chapter ' +
           'to be <span class="math">n/N</span>.  The average of the numbers on <span class="math">n</span> ' +
           'tickets drawn at random without replacement from the box can be written as ' +
           'a sum.  For <span class="math">j&nbsp;=&nbsp;1, 2, &hellip; , N</span>, ' +
           'let the variable <span class="math"><strong>I</strong><sub>j</sub></span> equal 1 ' +
           'if the <span class="math">j</span>th ticket is in the sample, and zero otherwise.  Then ' +
           '</p><p class="math">P(<strong>I</strong><sub>j</sub> = 1) = ' +
           'n/N, for j = 1, &hellip; , N, </p><p>and ' +
           '<p class="math">(sample mean) = (1/n) &times; <big>(</big> ' +
           'x<sub>1</sub>&times;<strong>I</strong><sub>1</sub> + ' +
           'x<sub>2</sub>&times;<strong>I</strong><sub>2</sub> + &hellip; + ' +
           'x<sub>N</sub>&times;<strong>I</strong><sub>N</sub> ' +
           '<big>)</big>. </p><p>The expected value of the sample mean is </p> ' +
           '<p class="math"> (1/n) &times; <big>(</big> ' +
           'x<sub>1</sub>&times;P(<strong>I</strong><sub>1</sub> = 1) + ' +
           'x<sub>2</sub>&times;P(<strong>I</strong><sub>2</sub> = 1) + ' +
           ' &hellip; + ' +
           'x<sub>N</sub>&times;P(<strong>I</strong><sub>N</sub> ' +
           '= 1) <big>)</big></p><p class="math"> = ' +
           '(1/n) &times; (n/N) &times; <big>(</big> ' +
           'x<sub>1</sub> + x<sub>2</sub> + &hellip; + ' +
           'x<sub>N</sub> <big>)</big></p><p class="math">' +
           '= (1/N) &times; <big>(</big> x<sub>1</sub> + ' +
           'x<sub>2</sub> + &hellip; + x<sub>N</sub> <big>)' +
           '</big>,</p><p>which is the average of the numbers on all the tickets in the ' +
           'box&mdash;the population mean.  Thus the sample mean is an unbiased estimator ' +
           'of the population mean under simple random sampling.'
           ;
    writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
    Thus the sample mean is an
    <a class="glossRef" href="gloss.htm#unbiased">unbiased</a>
    estimator of the population mean.
    Because a percentage is the mean of a list that consists of
    only zeros and ones, the
    <a class="glossRef" href="gloss.htm#sample_percentage">sample percentage</a>
    <span class="math">&phi;</span>
    is an unbiased estimator of the
    <a class="glossRef" href="gloss.htm#sample_percentage">population percentage</a>.
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'This also follows from what we already know about the ' +
       '<a class="glossRef" href="gloss.htm#hypergeometric_distrib">hypergeometric distribution</a> ' +
       'and properties of the <a class="glossRef" href="gloss.htm#expectation">expected value</a>: ' +
       'consider the objects labeled with ones to be &quot;good&quot; and those labeled ' +
       'with zeros to be &quot;bad.&quot; Then the number of &quot;good&quot; objects in a ' +
       'simple random sample of size <span class="math">n</span> has a hypergeometric distribution, ' +
       'which has expected value <span class="math">n&times;G/N</span>. ' +
       'The sample percentage <span class="math">&phi;</span> is the number of good objects in the ' +
       'sample, divided by <span class="math">n</span>, the size of the sample. Because </p>' +
       '<p class="math">E(the number of &quot;good&quot; objects in the sample ' +
       '/n) = E(the number of &quot;good&quot; objects in the sample)/n,</p>' +
       '<p class="math">E(&phi;) = ' +
       '(n&times;G/N)/n = G/N,</p>' +
       '<p>which is the population percentage.';
   writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
</p>
</div>

<p>
   Because the sample mean and sample percentage of simple random samples are
   unbiased estimators of the population mean and population percentage,
   respectively, they would seem to be reasonable estimators of those parameters.
   In fact, they are the most widely used estimators of the population mean and
   the population percentage.
   Because the sample mean and sample percentage are unbiased, their MSEs are the
   squares of their SEs, which we studied in
<script language="JavaScript1.8" type="text/javascript"><!--
    document.writeln(citeLinkChapter('standardError') + '. ');
// -->
</script>
</p>

<p>
<script language="JavaScript1.8" type="text/javascript"><!--
    citeFig();
// -->
</script>
    shows a tool to visualize the <a class="glossRef" href="gloss.htm#bias">bias</a>,
    <a class="glossRef" href="gloss.htm#se">SE</a>,
    and <a class="glossRef" href="gloss.htm#mse">MSE</a> of the sample mean and sample
    percentage under simple random sampling.
</p>

<div class="figure">
<script language="JavaScript1.8" type="text/javascript"><!--
    var qStr = 'Sampling distribution of the sample mean for simple random sampling.';
    writeFigureCaption(qStr);
// -->
</script>

<p class="figure">
    <div id="samp1" class="sampledist">
    </div>

    <script>
    jQuery(function() {
      new Stici_SampleDist('samp1', {
        variables: 'mean',
        startsWith: 'mean',
        boxContents: "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10",
        sources: 'box',
        boxHistControl: false,
        showBoxHist: false,
        replaceControl: false,
        curveControls: false,
        showCurve: false,
        sampleSize: 5,
        replace: false
      });
    });
    </script>
</p>

<script language="JavaScript1.8" type="text/javascript"><!--
    var randBoxContents = listOfRandInts(20,0,50).join(',');
    var appNum = (document.applets.length - 1).toString();
    sectionContext += 'document.applets[' + appNum + '].' +
              'setBox(randBoxContents,true);\n';
// -->
</script>
</div>

<p>
    Whenever you load this chapter, the box in
<script language="JavaScript1.8" type="text/javascript"><!--
    citeFig(figCtr-1);
// -->
</script>
    will be filled with 20 random integers between
    0 and 50, the sample size will be set to 5, and the number of samples to take
    will be set to 1.
    The average of the 20 numbers in the box is given as Ave(box)
    on the left of the figure;
    SD(box) is the <a class="glossRef" href="gloss.htm#sd">SD</a> of the numbers in the box.
    When you click <span class="appCtrlName">Take Sample</span>, the computer draws a pseudo-random
    sample of size 5 without replacement from the box, and computes the mean of those
    5 numbers.
    That mean is appended to a list of values of the sample mean from previous
    times you pushed the button.
    A histogram of that list of observed values of the
    sample mean is displayed and <span class="appCtrlName">Mean(values)</span> and
    <span class="appCtrlName">SD(values)</span> show the mean and SD of the list of observed values
    of the sample mean.
    If you alter the contents of the box, the process starts over.
</p>

<p>
    Click <span class="appCtrlName">Take Sample</span> a few times to get a feel for what happens.
    The values of the sample mean will tend to be scattered, and rarely will equal
    the average of the numbers on the box exactly.
    Then change the value of <span class="appCtrlName">Take_________Samples</span> to 1000, and draw
    a total of 10,000 samples of size 5.
    You should now see that there is some structure to the random values of the sample
    mean: The average of the observed values of the sample mean should be quite close to the
    expected value of the sample mean, and the SD of the observed
    values of the sample mean should
    be quite close to the SE of the sample mean.
    Try replacing the contents of the box with a list of only zeros and ones, to
    confirm that the same results hold for the population percentage and sample
    percentage.
</p>

<p>
    Recall that for a <a class="glossRef" href="gloss.htm#simple_random_sample">simple random sample</a>
    (a random sample without replacement)
    of size <span class="math">n</span> from a box of <span class="math">N</span> tickets labeled with numbers
    whose SD is SD(box),
</p>

<div align="center">
<center>
<table border="0">
    <tr>
    <td></td>
    <td></td>
    <td align="center">
        (<em>N</em> &minus; <em>n</em>)<sup>&frac12;</sup>
    </td>
    <td></td>
    <td align="center">
        SD(box)
    </td>
    </tr>
    <tr>
    <td align="center">
        SE(sample mean)
    </td>
    <td align="center">
        =
    <td align="center">
        ---------------
    </td>
    <td align="center">
        &times;
    </td>
    <td align="center">
        -------------- .
    </td>
    </tr>
    <tr>
    <td></td>
    <td></td>
    <td align="center">
        (<em>N</em> &minus; 1)<sup>&frac12;</sup>
    </td>
    <td></td>
    <td align="center">
        <em>n</em><sup>&frac12;</sup>
    </td>
    </tr>
</table>
</center>
</div>

<div class="indent">
<p class="inline">
    The first term in the product on the right hand side is the
    <a class="glossRef" href="gloss.htm#finite_population_correction">finite population correction</a>,
    and the second term is the SE of the sample mean for sampling with replacement.
    If the size of the population is much larger than the size of the sample
    (if <span class="math">N &gt;&gt; n</span>), there is not much difference
    between sampling with replacement and sampling without replacement,
    no matter how many ones or zeros are in the list,
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'The difference between sampling with replacement and without replacement is small ' +
               'if the chance is small that a sample drawn with replacement would draw any element more ' +
               'than once&mdash;because <em>demanding</em> that the <span class="math">n</span> members be ' +
               'distinct (i.e., sampling without replacement) doesn\'t change anything if the members would ' +
               'almost certainly have been distinct even without that demand (i.e., sampling with replacement). ' +
               'Equivalently, the difference between sampling with and without replacement is small if ' +
               'the chance is nearly one that a sample drawn without replacement would end up containing ' +
               '<span class="math">n</span> distinct members of the population. </p>' +
               '<p>So, what is the chance that a sample of size <span class="math">n</span> drawn with ' +
               'replacement from a population of size <span class="math">N</span> ends up containing ' +
               'exactly <span class="math">n</span> different members of the population? Let\'s think ' +
               'about drawing the sample sequentially. </p>' +
               '<p>The first draw always gives a member we haven\'t seen before, since we haven\'t ' +
               'seen anything before. What\'s the chance that the 2nd draw gives a member we haven\'t seen?</p>' +
               '<p>There are <span class="math">N&minus;1</span> members we haven\'t seen, and the ' +
               'second draw with replacement is equally likely to give any of the <span class="math">N</span> ' +
               'members in the population, so the chance is  <span class="math">(N&minus;1)/N</span>.</p>' +
               '<p>Given that the first and second draws give different members, what\'s the chance ' +
               'that the 3rd draw gives yet another member we haven\'t seen?  By the same reasoning, it\'s ' +
               '<span class="math">(N&minus;2)/N</span>.</p>' +
               '<p>Continuing this way, we can see that the chance that the <span class="math">n</span>th ' +
               'draw gives a member we haven\'t seen given that the first ' +
               '<span class="math">(n&minus;1)</span>st draws all gave distinct members of the population ' +
               'is <span class="math">(N&minus;(n&minus;1))/N.</p>' +
               '<p>The <a class="glossRef" href="gloss.htm#multiplication_rule">multiplication rule</a> ' +
               'tells us that the chance that all <span class="math">n</span> ' +
               'draws give distinct members is thus</p>' +
               '<p class="math">((N&minus;1)/N)&times;((N&minus;2)/N)&times; &hellip; ' +
               '&times;((N&minus;(n&minus;1))/N) = (N&minus;1)&times;(N&minus;2)&times; &hellip; ' +
               '&times;(N&minus;(n&minus;1))/N<sup>n&minus;1</sup>.</p>' +
               '<p>If all the ratios on the left are nearly 1 and there aren\'t too many of them, ' +
               'their product will be nearly one, and there isn\'t much difference between sampling with ' +
               'and without replacement.</p>' +
               '<p>The terms decrease (the numerators are getting smaller), so if ' +
               '<span class="math">(N&minus;(n&minus;1))<sup>n&minus;1</sup>/N<sup>n&minus;1</sup></span> is nearly ' +
               '<span class="math">1</span>, the probability will be nearly <span class="math">1</span>.' +
               'Now </p>' +
               '<p class="math">(N&minus;(n&minus;1))<sup>n&minus;1</sup>/N<sup>n&minus;1</sup> &ge; ' +
               '(N&minus;n)<sup>n&minus;1</sup>/N<sup>n&minus;1</sup> = ' +
               '(1 &minus; n/N)<sup>n-1</sup> &ge; 1 &minus; (n&minus;1)n/N</p>' +
               '<p>by <a class="glossRef" href="gloss.htm#bernoulli_inequality">Bernoulli\'s Inequality</a>.  ' +
               'So, if <span class="math">(n&minus;1)n/N</span> is very small ' +
               'compared to <span class="math">1</span>, there is little difference between sampling with ' +
               'replacement and sampling without replacement.';
    writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
    and the finite population correction is nearly unity&mdash;see
<script language="JavaScript1.8" type="text/javascript"><!--
    document.writeln(citeLinkChapter('standardError') + '. ');
// -->
</script>
</p>
</div>

<p>
    Suppose we did not know the contents of the box, but were told the size of the
    population (<span class="math">N</span>), and were given a simple random sample of size <span class="math">n</span>
    from the population.
    What might we infer about the population mean?
</p>

<p>
    It would be reasonable to guess that the sample mean was roughly equal to the
    population mean, give or take a random amount that is expected to be about one
    SE of the sample mean.
    Unfortunately, if we do not know the contents of the box, we are unlikely
    to know the SD of the numbers in the box, so we cannot calculate the
    SE of the sample mean.
    We would have an estimate of the population mean, but would have no
    idea how far off the estimate was likely to be (at least, not
    without extra work, as described presently).
</p>

<p>
    There are two common ways to estimate the uncertainty of the sample mean as
    an estimate of the population mean:
</p>

<ul>
    <li>
        For the sample percentage, there is a worst case&mdash;we can say with
        certainty that the SE of the sample percentage is no larger than a bound
        we can calculate without knowing the contents of the box.
    </li>
    <li>
        For both the sample percentage and the sample mean, we can use the sample
        to estimate the SD of the list of numbers in the box.
        The estimated SD of the box will itself have some uncertainty, but that
        uncertainty is small if the sample size is large.
    </li>
</ul>


<h3>
    <a id="conservative_se"></a>
    A Conservative Estimate of the
    SE of the Sample Percentage
</h3>

<p>
    For any list that contains only zeros and ones,
</p>

<p class="math">
    SD(list) &le; 50%,
</p>

<div class="indent">
<p class="inline">
    no matter how many ones or zeros are in the list.
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'Recall that the SD of a list of zeros and ones, with a fraction ' +
        '<span class="math">p</span> of ones, is</p><p class="math">' +
        '<big>(</big>p&times;(1 &minus; p) <big>)</big><sup>&frac12;</sup>.' +
        '</p><p>We would like to know how large this can be.  For positive arguments, ' +
        'the square-root function increases ' +
        '<a class="glossRef" href="gloss.htm#monotonic">monotonically</a>, so the value of ' +
        '<span class="math">p</span> that maximizes the SD also maximizes the square of the SD, ' +
        '</p><p class="math"></big>p&times;(1 &minus; p) = ' +
        'p &minus; p<sup>2</sup>.</p> <p>This is a quadratic function of ' +
        '<span class="math">p</span> with a negative leading coefficient, so its graph is a parabola ' +
        'that opens downwards: it has a well defined maximum. The maximum occurs ' +
        'at a stationary point&mdash;a point where the derivative of the function vanishes. ' +
        'Simple calculus shows that the derivative vanishes only when ' +
        '<span class="math">p = &frac12;</span>, ' +
        'which is between 0 and 1, so the maximum for <span class="math">p</span> between 0 and 1 is ' +
        'the value at <span class="math">p< = &frac12;</span>.  The corresponding value of the SD is ' +
        '</p><p class="math">' +
        '<big>(</big>&frac12;&times;(1 &minus; &frac12;) <big>)</big><sup>&frac12;</sup> = ' +
        '(1/4)<sup>&frac12;</sup> = &frac12;.';
    writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
    This worst case corresponds to a box of tickets of which 50% are labeled
    with zeros and 50% are labeled with ones; then
</p>
</div>

<p class="math">
    <a class="glossRef" href="gloss.htm#sd">SD</a>(box) =
    (0.5&times;0.5)<sup>&frac12;</sup> = 0.5
</p>
<p class="math">
    = 50%.
</p>

<p>
    Thus the <a class="glossRef" href="gloss.htm#se">SE</a> of the
    <a class="glossRef" href="gloss.htm#sample_percentage">sample percentage</a> for a simple random
    sample of size <span class="math">n</span> is at most
</p>

<p class="math">
    f &times; 50%/n<sup>&frac12;</sup>,
</p>

<p>
   where
</p>

<p class="math">
    f = <big>(</big>(N &minus; n)/(N &minus; 1)<big>)</big><sup>&frac12;</sup>
</p>

<p>
    is the <span class="termOfArt">finite population correction</span>.
</p>

<p>
    In summary, the sample percentage <span class="math">&phi;</span> of a simple random sample
    is a reasonable estimate of the population percentage,
    and its <a class="glossRef" href="gloss.htm#rmse">root mean squared error</a> is no larger than
</p>

<p class="math">
    f &times; 50%/n<sup>&frac12;</sup>.
</p>

<p>
    This estimate of the RMSE can be extremely conservative (i.e., much larger than the
    true RMSE of the sample percentage).
    We can use the sample itself to estimate
    the SD of the box, and hence the SE of the sample percentage or sample mean.
    If the sample size is large, the estimated SE
    is likely to be close to the true SE.</p>

<h3>
    <a id="bootstrap_sd"></a>
    The Bootstrap Estimate of the SD of a List of Zeros and Ones
</h3>

<p>
    The bootstrap estimates the uncertainty of the sample percentage by pretending that
    the sample is the population, and calculating the uncertainty the sample percentage
    <span class="math">&phi;</span>
    would have if we were drawing random samples repeatedly from the sample&mdash;as if the sample
    were the population.
    If we are sampling without replacement, we have to inflate the size of the sample
    to match the size of the population, by imagining we are sampling from a population
    the same size as the real population, but with a proportion of ones that matches the
    proportion of ones in the sample.
    That is, the bootstrap estimate of the SE of the sample percentage <span class="math">&phi;</span>
    is the SE the sample percentage would have if the proportion <span class="math">p</span> of ones in the
    box were equal to the proportion <span class="math">&phi;</span> of ones in the sample.
    This corresponds to estimating the SD of the box by the SD of the sample, namely,
</p>

<p class="math">
    (bootstrap estimate of SD) = s<sup>*</sup>= <big>(</big>
    (fraction of ones in the sample)&times;(fraction of zeros in the sample)
    <big>)</big><sup>&frac12;</sup>
</p>

<p class="math">
    = <big>(</big> &phi; &times; (1 &minus; &phi;)
    <big>)</big><sup>&frac12;</sup>
</p>

<p>
    If the sample is large, this is likely to be close to the SD of the box.
    If the sample size is small, the uncertainty in the bootstrap
    estimate of the SD is large.
</p>

<p>
    The corresponding bootstrap estimate of the standard error of the
    sample percentage, SE(<span class="math">&phi;</span>), is
</p>

<p class="math">
    (bootstrap estimate of SE of sample percentage) =
    f &times; s<sup>*</sup>/n<sup>&frac12;</sup>
</p>

<p class="math">
    = f &times; <big>(</big> &phi; &times; (1 &minus; &phi;)
    <big>)</big><sup>&frac12;</sup>/n<sup>&frac12;</sup>,
</p>

<p>
    where
</p>

<p class="math">
    f =
    <big>(</big> (N &minus; n)/(N&minus;1) <big>)</big><sup>&frac12;</sup>
</p>

<p>
    is the finite population correction.
</p>

<p>
    The following exercise checks your ability to compute the sample percentage,
    the upper bound on the SE of the sample percentage, and the bootstrap estimate
    of the SE of the sample percentage,
    and refreshes your knowledge of sampling designs.
</p>

<!-- ================================= START PROBLEM =================================== -->

<div class="problem">
<script language="JavaScript1.8" type="text/javascript"><!--
    document.writeln(startProblem(pCtr++));
    var nums = listOfDistinctRandInts(2,1,9).sort(numberLessThan);
    var N = 1000*nums[1]
    var n = 100*nums[0];
    var pHat = listOfRandInts(1,20,80)[0];
    var ph = pHat/100;
    var fpc = Math.sqrt((N-n + 0.0)/(N-1.0));
    var oneOverSqrtn = 1.0/Math.sqrt(n + 0.0);
    var seBnd = fpc*.5*oneOverSqrtn;
    var sdHat = Math.sqrt(ph*(1.0-ph));
    var seBoot = fpc*oneOverSqrtn*sdHat;
    var ansStr = '<p>The sample percentage <span class="math">&phi;</span> is an unbiased estimate of the ' +
         'population percentage, so we would estimate the population percentage ' +
         'to be ' + pHat.toString() + '%.  The conservative estimate of the ' +
         'standard error of the sample percentage uses the fact that the SD of ' +
         'a list of zeros and ones cannot exceed 50%.  That gives the upper bound ' +
         '</p><p class="math">SE(&phi;) &le; <big>(</big> ' +
         '(' + N.toString() + ' &minus; ' + n.toString() + ')<sup>&frac12;</sup>/(' +
         N.toString() + ' &minus; 1)<sup>&frac12;</sup> <big>)</big> &times; ' +
         n.toString() + '<sup>&minus;&frac12;</sup> &times; 50% = ' +
         roundToDig(100*seBnd,2) + '%. </p><p>The bootstrap estimate of the SE ' +
         'of the sample percentage estimates the SD of the box by the SD of the ' +
         'sample, which is </p<p class="math"><big>(</big> ' +
         roundToDig(pHat/100,3).toString() + ' &times; (1 &minus; ' + roundToDig(pHat/100,3).toString() +
         ' )<big>)</big><sup>&frac12;</sup> = ' + roundToDig(100*sdHat,2) +
         '%.</p><p>The bootstrap estimate of the SE of the sample percentage is ' +
         '</p><p class="math">estimated SE(sample percentage)  = <big>(</big> ' +
         '(' + N.toString() + ' &minus; ' + n.toString() + ')<sup>&frac12;</sup>/(' +
         N.toString() + ' &minus; 1)<sup>&frac12;</sup> <big>)</big> &times; ' +
         n.toString() + '<sup>&minus;&frac12;</sup> &times; ' +
         roundToDig(100*sdHat,2) + ' = ' +
         roundToDig(100*seBoot,2) + '%. </p><p>Although the sample from the ' +
         'collection (frame) of line officers is random, the frame bears ' +
         'no particular relation to the general population of line officers ' +
         'of corporations, so even though the sample results are ' +
         'likely to be representative of the frame, there is no reason to suppose ' +
         'that they are representative of the general population of line officers ' +
         'of U.S. corporations.</p>';
    document.writeln('A simple random sample of size ' + n.toString() + ' is taken from a ' +
    'collection of ' + commify(N) + ' line officers of U.S. corporations. ' +
    'Within the sample, ' + pHat.toString() + '% have salaries above $200,000. ' +
    '</p><p><span class="qSpan">An unbiased estimate of the fraction of the ' +
    'collection of ' + commify(N) + ' line officers whose salaries exceed ' +
    '$200,000 is </span>');
    writeTextExercise(8, qCtr++, numToRange(ph));
    document.writeln('</p><p><span class="qSpan">An upper bound on the standard error of ' +
    'this estimate is </span>');
    writeTextExercise(8, qCtr++, numToRange(seBnd));
    document.writeln('</p><p><span class="qSpan">The bootstrap estimate of the standard ' +
    'error of the estimate is </span>');
    writeTextExercise(8, qCtr++, numToRange(seBoot));
    document.writeln('</p><p><span class="qSpan">Is the estimated percentage likely to be ' +
    'about equal to the percentage of line officers of all U.S. corporations ' +
    'whose salaries exceed $200,000, give or take an SE or so? </span>');
    var opt = ["no","yes"];
    writeSelectExercise(false, qCtr++, opt, 'a');
    document.writeln('</p>');
    writeSolution(pCtr-1, ansStr);
// -->
</script>
</div>

<h3>
    <a id="s-squared"></a>
    Sample Standard Deviation and Sample Variance
</h3>

<p>
    The bootstrap estimate of the SD of the box can be used even when the box contains
    numbers other than only zeros and ones.
    The key idea of the bootstrap is to estimate the SD of the population by the SD of the sample:
</p>

<p class="math">
    estimated SD of box = s<sup>*</sup> = <big>(</big> (1/n) &times;
    ( (x<sub>1</sub> &minus; M)<sup>2</sup>
    + (x<sub>2</sub> &minus; M)<sup>2</sup> + &hellip; +
    (x<sub>n</sub> &minus; M)<sup>2</sup> )
    <big>)</big><sup>&frac12;</sup>,
</p>

<p>
    where <span class="math">{x<sub>1</sub>, x<sub>2</sub>, &hellip; ,
    x<sub>n</sub>}</span> are the data and
    <span class="math">M</span> is their sample mean:
</p>

<p class="math">
    M = (1/n) &times; <big>(</big>
    x<sub>1</sub> + x<sub>2</sub> + &hellip; +
    x<sub>n</sub> <big>)</big>.
</p>

<p>
    It turns out that the bootstrap estimate of the SD of the box is
    <a class="glossRef" href="gloss.htm#bias">biased</a>: Its expected value is less than the SD of
    the labels on the tickets in the box.
    The bias can be understood from the characterization of the
    <a class="glossRef" href="gloss.htm#mean">mean</a> as the number from
    which the <a class="glossRef" href="gloss.htm#rms">rms</a> of the
    <a class="glossRef" href="gloss.htm#deviation">deviations</a> is smallest&mdash;see
<script language="JavaScript1.8" type="text/javascript"><!--
    document.writeln(citeLinkChapter('location') + '. ');
// -->
</script>
    The rms of the deviations of the data from their own (sample) mean never is larger than,
    and typically is smaller than, the rms of the deviations of the data from the mean of the
    labels on all the tickets in the box (the population mean).
    The expected value of <span class="math">s<sup>*</sup></span>
    is the average of the possible values of <span class="math">s<sup>*</sup></span>,
    weighted by their probabilities.
    Each possible value is at most the rms of the deviations of the sample from the
    population mean, and typically less.
    The average is thus less than the average rms deviation of the numbers in the box
    from their population mean, so the expected value of <span class="math">s<sup>*</sup></span> is less
    than the SD of the list of numbers on the tickets in the box.
</p>

<p>
    For that reason, it is common to estimate the SD of the box using an estimator
    that takes a slightly larger value than <span class="math">s<sup>*</sup></span>, no matter what
    the sample happens to be.
    This more common estimator, called the <span class="termOfArt">sample standard deviation
    <span class="math">s</span></span>, differs
    only slightly from <span class="math">s<sup>*</sup></span>:
    <span class="math">s<sup>*</sup></span> divides by <span class="math">n</span>
    before taking the square root to form the rms of the residuals,
    while <span class="math">s</span> divides by <span class="math">n&minus;1</span>
    before taking the square root.
</p>

<p>&nbsp;</p>

<div class="callout">
        <p>
            <span class="calloutCaption"><a id="sample_sd"></a>
                The Sample Standard Deviation <span class="math">s</span></span>
        </p>
        <p>
            If there are <span class="math">n</span> data,
        </p>

        <p class="math">
            {x<sub>1</sub>,
            x<sub>2</sub>, &hellip; , x<sub>n</sub>},
        </p>

        <p>
            with sample mean
        </p>

        <p class="math">
            M = (x<sub>1</sub> +
            x<sub>2</sub> + &hellip; +
            x<sub>n</sub>)/n,
        </p>

        <p>
            then the sample standard deviation <span class="math">s</span> is defined by
        </p>
        <p class="math">
            s = <big>(</big> ((x<sub>1</sub> &minus;
            M)<sup>2</sup> +
            (x<sub>2</sub> &minus; M)<sup>2</sup> + &hellip; +
            (x<sub>n</sub> &minus;
            M)<sup>2</sup>)/(n&minus;1)
            <big>)</big><sup>&frac12;</sup>.
        </p>
</div>

<p>
    The relationship between <span class="math">s</span> and <span class="math">s<sup>*</sup></span> is
</p>

<p class="math">
    s =  s<sup>*</sup> &times; <big>(</big> n/(n&minus;1)
    <big>)</big><sup>&frac12;</sup> ,
</p>

<p>
    so <span class="math">s</span> is always larger than <span class="math">s<sup>*</sup></span>, by a fraction that
    is negligable when the sample size <span class="math">n</span> is large.
    Note that <span class="math">s<sup>*</sup></span> is the
    <span class="termOfArt">standard deviation of the sample</span>,
    while <span class="math">s</span> is the <span class="termOfArt">sample standard deviation</span>.
    For samples that contain only zeros and ones,
</p>

<p class="math">
   s = <big>(</big>(sample percentage)&times;(1 &minus; sample percentage)
           &times;n/(n&minus;1) <big>)</big><sup>&frac12;</sup>.
</p>

<p>
    When the box is known to contain only zeros and ones, it is more
    common to estimate the SD of the
    box by <span class="math">s<sup>*</sup></span> than by <span class="math">s</span>.
</p>

<div class="indent">
<p class="inline">
    For sampling <em>with</em> replacement,
    <span class="math">s<sup>2</sup></span> is an <a class="glossRef" href="gloss.htm#unbiased">unbiased</a>
    estimator of the square of the SD of the box.
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'It is not clear why this should be desirable: Typically, it is the ' +
           'SD of the box that is of interest, not the square of the SD (the population ' +
           'variance).  Moreover, for sampling without replacement, <span class="math">s<sup>2</sup></span> ' +
           'is a biased estimator of SD<sup>2</sup>.  Nonetheless, it is the most common ' +
           'estimator of the SD of the box when the box need not contain only zeros and ' +
           'ones.</p> <p>To show that <span class="math">s<sup>2</sup></span> is an ' +
           '<a class="glossRef" href="gloss.htm#unbiased">unbiased</a> estimator of the square of the ' +
           'SD of the population, we calculate the ' +
           '<a class="glossRef" href="gloss.htm#expectation">expected ' +
           'value</a> of <span class="math">s<sup>2</sup></span>.  Let ' +
           '<span class="math">M</span> denote the sample ' +
           'mean of the <span class="math">n</span> data, ' +
           '<span class="math">{X<sub>1</sub>, X<sub>2</sub>, &hellip; , ' +
           'X<sub>n</sub>}</span>, and let <span class="math">m</span> denote the ' +
           'population mean. </p><p class="math">E(s<sup>2</sup>) = ' +
           'E<big>(</big>(X<sub>1</sub> &minus; M)<sup>2</sup> + ' +
           '(X<sub>2</sub> &minus; M)<sup>2</sup> + &hellip; + ' +
           '(X<sub>n</sub> &minus; M)<sup>2</sup><big>)</big>/(n&minus;1)' +
           '</p><p class="math"> = <big>(</big>1/(n&minus;1)<big>)</big> ' +
           '&times; <big>(</big> E((X<sub>1</sub> &minus; M)<sup>2</sup>) + ' +
           'E((X<sub>2</sub> &minus; M)<sup>2</sup>) + &hellip; + ' +
           'E((X<sub>n</sub> &minus; M)<sup>2</sup> )<big>)</big></p>' +
           '<p class="math"> = <big>(</big>1/((n&minus;1)<big>)</big> ' +
           '&times; n &times; E((X<sub>1</sub> &minus; M)<sup>2</sup>)' +
           '</p><p>because all the the data have the same distribution. Now </p>' +
           '<p class="math">E((X<sub>1</sub> &minus; M)<sup>2</sup>) = ' +
           'E<big>(</big>(X<sub>1</sub> &minus; m) &minus; ' +
           '(M &minus; m)<big>)</big><sup>2</sup>' +
           '</p><p class="math"> = ' +
           'E<big>(</big>(X<sub>1</sub> &minus; m)<sup>2</sup> &minus; ' +
           '2(X<sub>1</sub> &minus; m)&times;(M &minus; m) + ' +
           '(M &minus; m)<sup>2</sup><big>)</big></p><p class="math">' +
           '= E(X<sub>1</sub> &minus; m)<sup>2</sup> &minus; ' +
           '2E<big>(</big>(X<sub>1</sub> &minus; ' +
           'm)&times;(M &minus; m)<big>)</big> + ' +
           'E(M &minus; m)<sup>2</sup>.</p><p>The first term, ' +
           '<span class="math">E(X<sub>1</sub> &minus; m)<sup>2</sup></span>, is the square of the ' +
           'SE of a single draw from the box (because the expected value of a single ' +
           'draw is the average of the box, <span class="math">m</span>), which the SD of the box squared ' +
           '(SD<sup>2</sup>). The third term, <span class="math">E(M &minus; m)<sup>2</sup></span>, ' +
           'is the square of the SE of the sample mean <span class="math">M</span> (because the ' +
           'expected value of the sample mean is <span class="math">m</span>), ' +
           'which is <span class="math">SD<sup>2</sup>/n</span>. The middle term is a bit harder. ' +
           'The factor <span class="math">(M &minus; m)</span> can be written</p><p class="math">' +
           '(X<sub>1</sub> &minus; m)/n + ' +
           '(X<sub>2</sub> &minus; m)/n + &hellip; ' +
           '(X<sub>n</sub> &minus; m)/n.</p><p>' +
           'The expected value of each of these terms is zero, because the expected ' +
           'value of each datum is <span class="math">m</span>.  The other factor in the middle term ' +
           'is <span class="math">(X<sub>1</sub> &minus; m)</span>; its expected value is also zero, ' +
           'for the same reason. The factor <span class="math">(X<sub>1</sub> &minus; m)</span> is ' +
           '<a class="glossRef" href="gloss.htm#independent">independent</a> ' +
           'of the terms <span class="math">(X<sub>2</sub> &minus; m)/n, ' +
           '(X<sub>3</sub> &minus; m)/n, &hellip;</span> , and ' +
           '<span class="math">(X<sub>n</sub> &minus; m)/n</span>, because the draws are ' +
           'independent.  Because the expected value of a product of independent ' +
           'random variables is the product of their expected values, we have</p>' +
           '<p class="math">E<big>(</big>(X<sub>1</sub> &minus; ' +
           'm)&times;(M &minus; m)<big>)</big></p>' +
           '<p class="math"> = E<big>(</big>(X<sub>1</sub> &minus; m) &times; ' +
           '(X<sub>1</sub> &minus; m)/n<big>)</big> + ' +
           'E<big>(</big>(X<sub>1</sub> &minus; m) &times; ' +
           '(X<sub>2</sub> &minus; m)/n<big>)</big> + ' +
           '&hellip; + E<big>(</big>(X<sub>1</sub> &minus; m) &times; ' +
           '(X<sub>n</sub> &minus; m)/n<big>)</big></p>' +
           '<p class="math"> = E<big>(</big>(X<sub>1</sub> &minus; m) &times; ' +
           '(X<sub>1</sub> &minus; m)/n<big>)</big> + ' +
           '0&times;0 + &hellip; + 0&times;0</p><p class="math"> = ' +
           '(1/n)&times;E(X<sub>1</sub> &minus; m)<sup>2</sup>.</p><p>' +
           'Because <span class="math">E(X<sub>1</sub>) = m</span>, the expected value is just the ' +
           'square of the SE of X<sub>1</sub>, which is SD<sup>2</sup>, so the ' +
           'middle term is <span class="math">2SD<sup>2</sup>/n</span>.  Combining ' +
           'all these results gives</p><p class="math">E(s<sup>2</sup> = ' +
           '<big>(</big>1/(n&minus;1)<big>)</big> &times; n &times; ' +
           '<big>(</big> SD<sup>2</sup> &minus; 2SD<sup>2</sup>/n + ' +
           'SD<sup>2</sup>/n <big>)</big></p><p class="math"> = ' +
           'SD<sup>2</sup>&times;<big>(</big>1/(n&minus;1)<big>)</big> &times; ' +
           'n &times;(1 &minus; 1/n) </p><p class="math"> = ' +
           'SD<sup>2</sup>&times;(n&minus;1)/(n&minus;1) = SD<sup>2</sup>.</p>' +
           'Thus <span class="math">s<sup>2</sup></span> is an unbiased estimator of the square of the ' +
           'SD of the box.';
    writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
    However, that does not imply that <span class="math">s</span> is an unbiased estimator of SD(box)
    (recall that <span class="math">E(X<sup>2</sup>)</span> typically is not equal to
    <span class="math">(E(X))<sup>2</sup></span>),
    nor is <span class="math">s<sup>2</sup></span> an unbiased estimator of the square
    of the SD of the box when the sample is drawn without replacement.
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'In sampling without replacement, <span class="math">s<sup>2</sup></span> is an unbiased ' +
           'estimator of the sum of the squares of the deviations of the population ' +
           'values from the population mean, divided by <span class="math">N&minus;1</span> instead of ' +
           '<span class="math">N</span>, which would give the variance of the numbers in the box.  Thus ' +
           'in sampling without replacement, <span class="math">s<sup>2</sup></span> will tend to ' +
           '<em>over</em>estimate the population variance.';
    writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
    The square of the SD of the box is called the
    <a class="glossRef" href="gloss.htm#variance">variance</a> of the population,
    the average of the squares of the <a class="glossRef" href="gloss.htm#deviation">deviations</a>
    of the numbers from their mean;
    <span class="math">s<sup>2</sup></span> is called the
    <a class="glossRef" href="gloss.htm#sample_variance">sample variance</a>.
</p>
</div>

<p>
<script language="JavaScript1.8" type="text/javascript"><!--
    citeFig();
// -->
</script>
    shows a tool to study the sampling distribution of the sample variance
    <span class="math">s<sup>2</sup></span>.
</p>

<div class="figure">
<script language="JavaScript1.8" type="text/javascript"><!--
    var qStr = 'Sampling distribution of the sample variance <span class="math">s<sup>2</sup></span>';
    writeFigureCaption(qStr);
// -->
</script>

<p class="figure">
    <div id="samp2" class="sampledist">
    </div>
    <script>
    jQuery(function() {
      new Stici_SampleDist('samp2', {
        variables: 's-squared',
        startsWith: 's-squared',
        boxContents: "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10",
        sources: 'box',
        boxHistControl: false,
        showBoxHist: false,
        replaceControl: true,
        curveControls: false,
        showCurve: false,
        sampleSize: 5,
        replace: false
      });
    });
    </script>
</p>

<script language="JavaScript1.8" type="text/javascript"><!--
    var appNum = (document.applets.length - 1).toString();
    sectionContext += 'document.applets[' + appNum + '].' +
              'setBox(randBoxContents,true);\n';
// -->
</script>
</div>

<p>
    Use
<script language="JavaScript1.8" type="text/javascript"><!--
    citeFig(figCtr-1);
// -->
</script>
    to draw 10,000 samples from the box with and without replacement.
    Note that the average of the observed values of <span class="math">s<sup>2</sup></span> approaches
    its expected value in both cases.
    However, the expected value of <span class="math">s<sup>2</sup></span> is the square of the SD of the
    contents of the box (the population variance) when the sample is drawn with replacement,
    but larger than the population variance when the sample is drawn without replacement.
</p>

<p>
    We now have the ingredients to estimate the population mean, and to estimate
    the SE of the estimate of the population mean:
</p>

<div class="callout">
        <p>
             <span class="calloutCaption">Estimating the population mean or percentage</span>
        </p>
        <p>
            Consider a random sample of size <span class="math">n</span> from a population
            of size <span class="math">N</span>, taken with or without replacement.
        </p>
        <p>
            The sample mean and sample percentage are unbiased estimates
            of the population mean and population percentage.
        </p>
        <ul>
            <li>
            For a random sample without replacement, the standard error of the
            sample percentage is no larger than
            <span class="math">f&times;50%/n<sup>&frac12;</sup></span>,
            where <span class="math">f</span> is the
            <a class="glossRef" href="gloss.htm#finite_population_correction">finite population
            correction</a>.
            </li>
            <li>
            For a random sample with replacement, the standard error of the
            sample percentage is no larger than
            <span class="math">50%/n<sup>&frac12;</sup></span>.
            </li>
            <li>
            For large random samples with replacement,
            the <a class="glossRef" href="gloss.htm#sample_sd">sample standard deviation
            <span class="math">s</span></a>
            and the <a class="glossRef" href="gloss.htm#bootstrap">bootstrap</a> estimate
            of the SD of the box, <span class="math">s<sup>*</sup></span> both are likely to be
            close to the SD of the population.
            <span class="math">s<sup>*</sup>/n<sup>&frac12;</sup></span>
            is a common estimate of the SE of the sample percentage,
            and
            <span class="math">s/n<sup>&frac12;</sup></span> is a common estimate
            of the SE of the sample mean.
            </li>
            <li>
            For random samples without replacement,
            <span class="math">f&times;s<sup>*</sup>/n<sup>&frac12;</sup></span>
            is a common estimate of the SE of the sample percentage,
            and <span class="math">f&times;s/n<sup>&frac12;</sup></span>
            is a common estimate of the SE of the sample mean.
            </li>
            <li>
                For random samples with replacement, <span class="math">s<sup>2</sup></span> is
                an unbiased estimate of SD<sup>2</sup>, the square of the
                population standard deviation, also called the <span class="termOfArt">population variance</span>.
            </li>
        </ul>
</div>

<p>
    The following example illustrates using the sample mean to estimate the population mean.
    The example is dynamic: The data tend to change when you reload the page.
</p>

<div class="example">
<script language="JavaScript1.8" type="text/javascript"><!--
    var qStr = 'Estimating a Population Mean and the SE of the Estimate';
    writeExampleCaption(qStr);
// -->
</script>

<p>
<script language="JavaScript1.8" type="text/javascript"><!--
    var sizes = listOfDistinctRandInts(2,2,6).sort(numberLessThan);
    var popSize = 1000*sizes[1];
    var samSize = 4*sizes[0];
    var wts = normPoints(samSize,130,15,2);
    var wtMean = mean(wts);
    var wtSum = vSum(wts);
    var wtSd = sampleSd(wts);
    var sqDev = new Array(samSize);
    for (var i=0; i < samSize; i++) {
        sqDev[i] = roundToDig((wts[i] - wtMean)*(wts[i] - wtMean),5);
    }
    var list = [wts, sqDev];
    var ssq = roundToDig(vSum(sqDev),4);
    var ssqMean = roundToDig(ssq/(samSize-1.0),4);
    var sStr = roundToDig(Math.sqrt(ssq/(samSize-1.0)),4).toString();
    var fpc = Math.sqrt((popSize - samSize)/(popSize - 1.0));
    var seStr = roundToDig(fpc*wtSd/(Math.sqrt(samSize)),3);
    var qStr = 'A simple random sample of size ' + cardinals[samSize] +
               ' is drawn from a population of ' +  popSize.toString() +
               ' people.  Their weights were measured to be</p><p>';
    document.writeln(qStr);
    var header = 'Weight (lbs.)';
    listToTable(header,wts,'transpose','center');
    qStr = '<p>&nbsp;</p><p>Let us estimate the average weight of the population ' +
           'from which the sample was drawn, and the error of our estimate.</p><p>' +
           'The sample mean is the sum of these ' + cardinals[samSize] +
           ' measured values, divided by ' + samSize.toString() + '; namely, ' +
           roundToDig(wtMean,3).toString() + '. That is our estimate of the average ' +
           'weight of the population.  To estimate the uncertainty in the estimate, we ' +
           'calculate <span class="math">s</span>, the sample standard deviation.  ' +
           'To find <span class="math">s</span>, we ' +
           'sum the squares of the deviations of the observed values from their sample ' +
           'mean, divide the result by ' + (samSize-1).toString() + ', then take the square root. ' +
           'Here are the data and the squares of their deviations from the sample mean: ';
    document.writeln(qStr);
    var header = ['Weight (lbs.)','squared deviation (lbs.<sup>2</sup>)'];
    listToTable(header,list,"transpose","center");
    qStr = '</p><p>The sum of the squared deviations is ' + ssq.toString() +
           ' lbs.<sup>2</sup>. Dividing this by ' + (samSize-1).toString() +
           ' yields ' + ssqMean.toString() + ' lbs.<sup>2</sup>.  Taking the square root gives ' +
           '</p><p class="math">s = ' + sStr + ' lbs. </p><p> The finite population ' +
           'correction is </p><p class="math">f = <big>(</big> (' + popSize.toString() +
           ' &minus; ' + samSize.toString() + ')/(' + popSize.toString() + ' &minus; 1) ' +
           '<big>)</big><sup>&frac12;</sup> = ' + roundToDig(fpc,6).toString() + '.</p><p> ' +
           'Our estimate of the SE of the sample mean is</p><p class="math">' +
           'f&times;s/n<sup>&frac12;</sup> ' +
           '= ' + seStr + ' lbs. </p><p>We thus would estimate the average weight ' +
           'within the population from which the sample was drawn to be ' +
           roundToDig(wtMean,3).toString() + ' lbs., give or take ' + 'about ' + seStr + ' lbs.</p>';
    document.writeln(qStr);
// -->
</script>
</p>
</div>

<p>
    The following exercise checks your ability to estimate the population mean
    from the sample mean, and to estimate the uncertainty of that estimate.
    The exercise is dynamic: The data tend to change when you reload the page.
</p>

<div class="problem">
<script language="JavaScript1.8" type="text/javascript"><!--
    document.writeln(startProblem(pCtr++));
    var sizes = listOfDistinctRandInts(2,2,6).sort(numberLessThan);
    var popSize = 1000*sizes[1];
    var samSize = 4*sizes[0];
    var wts = normPoints(samSize,50,3,2);
    var wtMean = mean(wts);
    var wtSum = vSum(wts);
    var wtSd = sampleSd(wts);
    var sqDev = new Array(samSize);
    for (var i=0; i < samSize; i++) {
        sqDev[i] = roundToDig((wts[i] - wtMean)*(wts[i] - wtMean),5);
    }
    var list = [wts, sqDev];
    var ssq = roundToDig(vSum(sqDev),4);
    var ssqMean = roundToDig(ssq/(samSize-1.0),4);
    var sStr = roundToDig(Math.sqrt(ssq/(samSize-1.0)),4).toString();
    var fpc = Math.sqrt((popSize - samSize)/(popSize - 1.0));
    var seStr = roundToDig(fpc*wtSd/(Math.sqrt(samSize)),3);
    var header = "Lifetimes (100s of hours)";
    var qStr = 'A simple random sample of size ' + cardinals[samSize] +
           ' is drawn from a population of ' + popSize.toString() +
           ' fluorescent lightbulbs. The bulbs were run until they failed. ' +
           'The failure times were </p>' +
           listToTable(header,wts,"transpose","center", false) +
           '<p><span class="qSpan">The estimated average failure time ' +
           '(in hundreds of hours) for the population of bulbs is</span>';
    document.writeln(qStr);
    writeTextExercise(10,qCtr++,numToRange(wtMean));
    var qStr = '<span class="qSpan">, give or take about </span>';
    document.writeln(qStr);
    writeTextExercise(10,qCtr++,numToRange(fpc*sampleSd(wts)/Math.sqrt(samSize)));
    var qStr = '<span class="qSpan"> hundred hours.</span></p>';
    document.writeln(qStr);
    var ansStr = '<p>The sample mean is our estimate of the average lifetime within the ' +
         'population.  The sample mean is the sum of the measured values, divided ' +
         'by the sample size, ' + samSize.toString() + '; namely, ' +
         roundToDig(wtMean,3).toString() + '. The sample standard deviation ' +
         '<span class="math">s</span> is square root of 1/(' + (samSize-1).toString() + ') times ' +
         'the sum of the squares of the deviations of the observed values from ' +
         'their sample mean. The sum of the squared deviations is ' + ssq.toString() +
         ' (hundred hours)<sup>2</sup>. Dividing this by ' + (samSize-1).toString() +
         ' yields ' + ssqMean.toString() +
         ' (hundred hours)<sup>2</sup>.  Taking the square root gives ' +
         '</p><p class="math">s = ' + sStr + ' hundred hours.</p><p> ' +
         'The finite population correction is </p>' +
         '<p class="math">f = <big>(</big> (' +
         popSize.toString() + ' &minus; ' + samSize.toString() +
         ')/(' + popSize.toString() + ' &minus; 1) <big>)</big><sup>&frac12;</sup> = ' +
         roundToDig(fpc,6).toString() + '.</p><p> ' +
         'Our estimate of the SE of the sample mean is ' +
         '</p><p class="math">f&times;s/n<sup>&frac12;</sup> ' +
         '= ' + seStr + ' hundred hours</p><p>We thus would estimate the ' +
         'average lifetime within the population from which the ' +
         'sample was drawn to be ' + roundToDig(wtMean,3).toString() +
         ' hundred hours, give or take about ' + seStr + ' hundred hours </p>';
    writeSolution(pCtr-1, ansStr);
// -->
</script>
</div>

<p>
    If the sample size is small enough, relative to the size of the
    population, then the <a class="glossRef" href="gloss.htm#finite_population_correction">finite population
    correction</a> is close to one, and the <a class="glossRef" href="gloss.htm#se">SE</a> of the
    <a class="glossRef" href="gloss.htm#sample_mean">sample mean</a> essentially
    depends only on the sample size <span class="math">n</span>, and not the
    population size <span class="math">N</span>.
</p>

<p>
    For example, suppose we seek to estimate the percentage of Democrats in the San
    Francisco Bay Area, and in the United States as a whole, using the sample percentages
    of simple random samples of size 3000.
    Because 3000 is but a small fraction of either population, the SE of the two sample
    percentages would be about the same, assuming that the percentage of Democrats in
    the San Francisco Bay area is not that different from the percentage in the
    United States as a whole, even though the United States has a much larger population
    than the Bay Area.
</p>

<p>
    Some studies report a <a class="glossRef" href="gloss.htm#margin_of_error">margin of error</a> for
    a parameter estimates.
    This is particularly common for sample surveys.
    &quot;Margin of error&quot; does not have a widely accepted definition,
    but typically it is either one or two times the estimated SE of the parameter estimate.
</p>

<p>
    The following exercises check your ability to estimate population percentages,
    and your understanding of the dependence of the SE of the sample mean and sample
    percentage on the sample size.
    The exercises are dynamic: The data tend to change when you reload the page.
</p>

<!-- ==================================START PROBLEM==================================== -->

<div class="problem">
<script language="JavaScript1.8" type="text/javascript"><!--
   document.writeln(startProblem(pCtr++));
   var seatPop = 1000*(listOfRandInts(1,5,10))[0];
   var seatSam = 100*(listOfRandInts(1,1,3))[0];
   var fDef = (listOfRandReals(1,.01,.08))[0];
   var nDef = Math.floor(fDef*seatSam);
   var fDef = nDef/seatSam;
   var fStr = (roundToDig(100*fDef,2)).toString();
   var SEfBoot = Math.sqrt((seatPop - seatSam)/(seatPop-1))*Math.sqrt(fDef*(1-fDef)/seatSam);
   var SEfBnd =  Math.sqrt((seatPop - seatSam)/((seatPop-1)*seatSam))*0.5;
   var ansStr = '<p>The sample percentage <span class="math">&phi;</span> is an estimator used to estimate ' +
        'the percentage of defective seats manufactured that year; the seats ' +
        'manufactured that year comprise the population. ' +
        'The sample percentage <span class="math">&phi;</span>  of defectives is the same as the ' +
        'estimated fraction of defective seats in the manufacturing lot:</p>' +
        '<p class="math">' +
        '(#defective in sample)/(size of sample) = ' + nDef.toString() + '/' +
        seatSam.toString() + ' = ' + fStr + '%.</p><p> ' +
        'The bootstrap estimate of the standard error assumes that the ' +
        'fraction of defectives in the sample is the same as the fraction of ' +
        'defectives in the population; the corresponding estimate of the standard ' +
        'error of the sample percentage is ' +
        '</p><p class="math"><big>(</big>(' + seatPop.toString() + ' &minus; ' +
        seatSam.toString() + ')/(' + seatPop.toString() + ' &minus; 1)<big>)</big><sup>' +
        '&frac12;</sup> &times; <big>(</big> ' + fStr + '% &times;(1 &minus; ' + fStr +
        '%)/' + seatSam.toString() + '<big>)</big><sup>&frac12;</sup> = ' +
        (roundToDig(100*SEfBoot,2)).toString() + '%.</p><p>We get an upper bound ' +
        'on the SE of the sample percentage by assuming ' +
        'that the population percentage is 50%, which gives </p><p class="math">' +
        'SE(sample percentage of defectives) &le; ' +
        '<big>(</big>(' + seatPop.toString() + ' &minus; ' +
        seatSam.toString() + ')/(' + seatPop.toString() + ' &minus; 1)<big>)</big><sup>' +
        '&frac12;</sup> &times; <big>(</big>&frac12; &times;(1 &minus; &frac12;)' +
        ')/' + seatSam.toString() + '<big>)</big><sup>&frac12;</sup> = '
        + (roundToDig(100*SEfBnd,2)).toString() + '%.</p> ';
    var qStr = 'A consumer advocacy group is concerned about the safety of child seats ' +
           'made by a particular manufacturer.  The group takes a simple random ' +
           'sample of ' + seatSam.toString() + ' of the ' + seatPop.toString() +
           ' seats made by the manufacturer in a given year. ' + nDef.toString() +
           ' of the seats are found to have safety defects.</p><p><span class="qSpan">' +
           'Which is the parameter?</span>';
    document.writeln(qStr);
    var opt = ["the number of defective seats in the sample",
           "the percentage of defective seats in the sample",
           "the percentage of seats made by the manufacturer that year that have defects"
          ];
    writeSelectExercise(false, qCtr++, opt,"c");
    var qStr = '</p><p><span class="qSpan">What is the sample percentage of defective ' +
           'seats?</span>';
    document.writeln(qStr);
    writeTextExercise(8, qCtr++, numToRange(fDef));
    var qStr = '</p><p><span class="qSpan">What is the estimated fraction of defective ' +
           'seats in the population of seats made by the manufacturer in the year ' +
           'in question?</span>';
    document.writeln(qStr);
    writeTextExercise(8, qCtr++, numToRange(fDef));
    var qStr = '</p><p><span class="qSpan">What is the bootstrap estimate of the ' +
           'standard error of the estimate?</span>';
    document.writeln(qStr);
    writeTextExercise(8, qCtr++, numToRange(SEfBoot));
    var qStr = '</p><p><span class="qSpan">What is the largest the standard error of ' +
           'the sample percentage of defective seats could be?</span>';
    document.writeln(qStr);
    writeTextExercise(8, qCtr++, numToRange(SEfBnd));
    document.writeln('</p>');
    writeSolution(pCtr-1,ansStr);
// -->
</script>
</div>

<!-- ==================================START PROBLEM==================================== -->

<div class="problem">
<script language="JavaScript1.8" type="text/javascript"><!--
   document.writeln(startProblem(pCtr++));
   var smalln = 10*(listOfRandInts(1,5,15))[0];
   var popSize = smalln*(listOfRandInts(1,10,20))[0];
   var halfSize = Math.ceil(popSize/(popSize/(4*smalln) + 0.75));
   var ansStr = '<p>The SE of the sample percentage for a simple random sample of size ' +
        '<span class="math">n</span> from a population of ' + popSize.toString() + ' is</p>' +
        '<p class="math"><big>(</big>(' + popSize.toString() +
        ' &minus; n)/(' + popSize.toString() + ' &minus; 1)<big>)</big><sup>&frac12;</sup>' +
        '&times;n<sup>&minus;&frac12;</sup> &times; <big>(</big> p &times; ' +
        '(1&minus;p) <big>)</big><sup>&frac12;</sup>,</p><p>where <span class="math">p</span> is ' +
        'the (unknown) population percentage.  We seek the value of <span class="math">n</span> ' +
        'such that the ratio of the SE for a sample of size <span class="math">n</span> to the SE ' +
        'for a sample of size ' + smalln.toString() + ' is &frac12;.  In the ratio, ' +
        'the terms involving the unknown <span class="math">p</span> (the SD of the "box") cancel, as ' +
        'do the factors of (' + popSize.toString() + ' &minus; 1)<sup>&frac12;</sup>; ' +
        'the ratio simplifies to</p><p class="math">(SE for sample size n)/' +
        '(SE for sample size ' + smalln.toString() + ') = &frac12; = ' +
        '<big>(</big>(' + popSize.toString() + ' &minus; n)/(' + popSize.toString() +
        ' &minus; ' + smalln.toString() + ')<big>)</big><sup>&frac12;</sup> &times; ' +
        smalln.toString() + '<sup>&frac12;</sup>/n<sup>&frac12;</sup>.</p>' +
        '<p>Squaring both sides of this equation yields</p><p class="math">' +
        '1/4 = (' + popSize.toString() + ' &minus; n)/(' + popSize.toString() +
        ' &minus; ' + smalln.toString() + ') &times; ' + smalln.toString() + '/n.' +
        '</p><p>Collecting terms involving <span class="math">n</span> gives </p><p class="math">' +
        '(' + popSize.toString() + ' &minus; n)/n = 1/4 &times; (' +
        popSize.toString() + ' &minus; ' + smalln.toString() + ')/' + smalln.toString() +
        ', or </p><p class="math">' + popSize.toString() + '/n &minus; 1 = ' +
        '1/4 &times; (' + popSize.toString() + '/' + smalln.toString() + ' &minus; 1)</p>' +
        '<p class="math">' + popSize.toString() + '/n = 1/4 &times; ' +
        popSize.toString() + '/' + smalln.toString() + ' + 3/4 </p>' +
        '<p class="math">1/n = <big>(</big>1/4&times;' +
        popSize.toString() + '/' + smalln.toString() + ' + 3/4<big>)</big>/' +
        popSize.toString() + '</p>' +
        '<p class="math">n = ' + popSize.toString() + '/<big>(</big>' +
        popSize.toString() + '/(4&times;' + smalln.toString() + ') + 3/4<big>)</big> = ' +
        (roundToDig(popSize/(popSize/(4*smalln) + 0.75),2)).toString() + '.</p><p>' +
        'The sample size must be an integer.  The smallest integer at least this ' +
        'big is ' +
        (roundToDig(Math.ceil(popSize/(popSize/(4*smalln) + 0.75)),0)).toString() +
        '. Note that this is considerably less than four times the sample size of ' +
        smalln.toString() + ', which is the sample size we would need to halve ' +
        'the SE if the sample were taken <em>with</em> replacement.</p>';
    var qStr = 'I wish to estimate a population percentage using the sample percentage ' +
           'computed from a simple random sample. The population consists of ' +
        popSize.toString()  + ' units. </p><p><span class="qSpan">How large a ' +
        'simple random sample would be needed for the SE of the sample percentage ' +
        'to be no more than half the SE of the sample percentage for a simple ' +
        'random sample of size ' + smalln.toString()   + '? </span>';
    document.writeln(qStr);
    writeTextExercise(8, qCtr++, numToRange(halfSize,.01));
    document.writeln('</p>');
    writeSolution(pCtr-1,ansStr);
// -->
</script>
</div>

<!-- ==================================START PROBLEM==================================== -->

<div class="problem">
<script language="JavaScript1.8" type="text/javascript"><!--
    document.writeln(startProblem(pCtr++));
    var pctTol = (listOfRandInts(1,1,4))[0];
    var pctCtn = (listOfRandInts(1,90,99))[0];
    var zscore = -roundToDig(normInv((1-pctCtn/100)/2),3);
    var zprod = roundToDig(.01*pctTol/zscore,6);
    var samSqrt = roundToDig(.5/zprod,3);
    var sam = roundToDig(Math.ceil(samSqrt*samSqrt),0);
    var chebyBnd = Math.sqrt(100/(100-pctCtn));
    var chebyStr = roundToDig(chebyBnd, 3).toString();
    // k = sqrt(1/(1-pCtn))
    // k*SE < pTol
    // SE <= .5/sqrt(n)
    // k*.5/sqrt(n) < pTol
    // sqrt(1/(1-pCtn))*.5/sqrt(n) < pTol
    // sqrt(n) > sqrt(1/(1-pCtn))*.5/pTol;
    var chebySam = Math.pow(chebyBnd*.5/(pctTol/100),2);
    var chebySamInt = Math.ceil(chebySam);
    var ansStr = '<p>The population of registered voters is quite large. If ' +
        'it turns out that the sample size we infer we would need on the ' +
        'assumption that the sampling is without replacement is small, then there ' +
        'would not have been much difference between sampling with and without ' +
        'replacement for our sample size. We shall start by assuming that the ' +
        'required sample size is small compared with the population, and verify ' +
        'whether that assumption was reasonable when we finish. Similarly, we ' +
        'shall assume that the sample size is sufficiently large that the normal ' +
        'approximation to the sample percentage is adequate. </p> ' +
        '<p>The SE of the sample percentage is at most ' +
        '<span class="math">50%/n<sup>&frac12;</sup></span>. To apply the normal approximation, we ' +
        'want to know what symmetric range of standard units gives an area under ' +
        'the normal curve equal to ' + pctCtn.toString() + '%:</p> ' +
        '<p class="figure"> ' +
        '<div id="normhilite1" class="curvehilite"></div>' +
        '</p> ' +
        '<p> Using the normal approximation, the chance that the sample percentage ' +
        'would be within &plusmn;' + zscore.toString() + 'SE of the population  ' +
        'percentage is about ' + pctCtn.toString() + '%. ' +
        'We thus want ' + zscore.toString() + 'SE to be at most ' +
        pctTol.toString() + '%. This gives</p> ' +
        '<p class="math">1SE &le; ' + pctTol.toString() + '%/' + zscore.toString() +
        ' = ' + zprod.toString() + '.</p> ' +
        '<p>Because the SE is no larger than <span class="math">50%/n<sup>&frac12;</sup></span> (no ' +
        'matter what the population percentage happens to be), we can be sure that ' +
        '1SE is no larger than ' + zprod.toString() + ' if </p> ' +
        '<p class="math">50%/n<sup>&frac12;</sup> &le; ' +
        zprod.toString() + '</p><p class="math">50%/' + zprod.toString() +
        ' &le; n<sup>&frac12;</sup></p><p class="math">' +
        samSqrt.toString() + ' &le; ' +
        'n<sup>&frac12;</sup></p><p class="math">n &ge; ' +
        sam.toString() + '.</p> ' +
        '<p>This is large enough that the normal approximation should be quite ' +
        'accurate, but small enough compared with the population of registered ' +
        'voters that there should be little difference between sampling with ' +
        'and without replacement, so the assumptions/approximations we used are ' +
        'justified: a sample size of ' + sam.toString() +
        ' ensures that there is (at least) a ' +
        pctCtn.toString() + '% chance that the sample percentage will be within ' +
        '&plusmn;' + pctTol.toString() + '% of the population percentage. The ' +
        'probability will tend to be greater than ' + pctCtn.toString() +
        '% unless the population percentage <span class="math">p</span> happens to be 50%.</p><p>' +
        'The sample size is sufficiently large that the normal approximation should ' +
        'be quite good.  However, if the sample size were smaller, we could ' +
        'answer conservatively by using Chebychev\'s inequality to determine ' +
        'the bound on the probability in terms of the SD of the box.  The chance that ' +
        'the sample percentage is within ' + chebyStr +
        ' SE of its expected value is at least ' + pctCtn.toString() + '.  Thus ' +
        'if we pick the sample size so that '  + chebyStr + ' times the ' +
        'standard error of the percentage cannot exceed ' + pctTol.toString() +
        '%, we have a conservative ' +
        'bound; <em>i.e.</em>, we want the SE to be no greater than ' +
        pctTol.toString() + '%/' +
        chebyStr + ' = ' + roundToDig(pctTol/chebyBnd, 3).toString() + '%.  The SE ' +
        'is no larger than 50% divided by the square root of the sample size, so ' +
        'if the sample size is at least ' + chebySamInt + ', the chance that the ' +
        'sample percentage is within ' + pctTol.toString() + '% of the population ' +
        'percentage is at least ' + pctCtn.toString() + '%. Probably this is ' +
        'extremely conservative.</p>';
    var qStr = 'I wish to use a simple random sample to estimate the percentage of ' +
           'registered US voters who believe that the United States should pay the ' +
           'United Nations what it owes in back dues. <span class="qSpan">' +
           'How large a sample must I take to be sure that the chance is at ' +
           'least ' + pctCtn.toString() +
           '% that the sample percentage is within &plusmn;' + pctTol.toString() +
           '% of the population percentage? </span>';
    document.writeln(qStr);
    writeTextExercise(8, qCtr++, numToRange(sam,0.1));
    document.writeln('</p>');
    writeSolution(pCtr-1,ansStr);
    jQuery(function() {
          new Stici_NormHiLite('normhilite1', {
            hiLiteHi:  (zscore).toString(),
            hiLiteLo:  (-zscore).toString()
          });
        });
// -->
</script>
</p>
</div>

<h2>
    <a id="caveats"></a>
    Caveats
</h2>

<p>
    The formulae in this chapter are for simple random sampling, and, in some cases,
    sampling with replacement with equal probability of selecting each unit.
    They do not apply to any other sampling design.
    In particular, unless the sample is selected at random, the error in the
    sample mean cannot be decomposed into bias and sampling error&mdash;there is no
    way to quantify &quot;the luck of the draw.&quot;
    If the sample is selected at random, but not by simple random sampling or sampling
    with replacement, other formulae can be derived to quantify the bias and
    standard error of the sample mean.
</p>

<div class="indent">
<p class="inline">
    For example, if the sample is drawn at random in such a way that every unit in
    the population has the same chance of being in the sample, the sample mean will be
    an unbiased estimator of the population mean.
<script language="JavaScript1.8" type="text/javascript"><!--
    var fStr = 'It is straightforward to calculate the expected value of the sample ' +
           'mean when every unit has the same chance of being in the sample. ' +
           'Let <span class="math">p</span> denote the (common) chance that each unit is in the ' +
           'sample, and let <span class="math">I<sub>j</sub></span> equal 1 if the <span class="math">j</span>th ' +
           'unit is in the sample, and 0 if not.  Let ' +
           '<span class="math">x<sub>j</sub></span> denote the value of the ' +
           '<span class="math">j</span>th unit. Then the sample mean is </p>' +
           '<p class="math">(1/n) &times; <big>(</big> ' +
           'x<sub>1</sub>&times;I<sub>1</sub> + ' +
           'x<sub>2</sub>&times;I<sub>2</sub> + &hellip; + ' +
           'x<sub>N</sub>&times;I<sub>N</sub> ' +
           '<big>)</big>. </p><p> The expected value of <span class="math">I<sub>j</sub></span> is ' +
           '<span class="math">p</span>, so the expected value of the sample mean is </p>' +
           '<p class="math">p/n &times; <big>(</big> ' +
           'x<sub>1</sub> + x<sub>2</sub> + ' +
           '&hellip; + ' +
           'x<sub>N</sub> <big>)</big>. </p><p>If the chance each ' +
           'unit is in the sample is <span class="math">p = n/N</span>, then ' +
           'this equals the population mean, and the sample mean is thus ' +
           'unbiased.</p><p>Now the sample size is always <span class="math">n</span>, so the ' +
           'expected value of the sample size is <span class="math">n</span>.  The sample size is ' +
           '</p><p class="math">I<sub>1</sub> + I<sub>2</sub> + ' +
           '&hellip; + ' +
           'I<sub>N</sub>,</p><p>so the expected value of the sample size ' +
           'is <span class="math">N&times;p</span>.  Thus </p><p class="math">' +
           'n = N&times;p;</p><p>hence <span class="math">p = ' +
           'm/N</span> and the sample mean is unbiased.';
    writeFootnote(fCtr++, fCtr.toString(), fStr);
// -->
</script>
    However, the SE of the sample mean depends crucially on the sample design.
</p>
</div>

<h2> <a id="summary"></a>
    Summary
</h2>

<p>
    An <span class="termOfArt">estimator</span> is a
    <a class="glossRef" href="gloss.htm#statistic">statistic</a>,
    a number calculated from a sample to estimate a population
    <a class="glossRef" href="gloss.htm#parameter">parameter</a>.
    Consider an estimator <span class="math">X</span> of a parameter <span class="math">t</span> calculated from a
    <a class="glossRef" href="gloss.htm#probability_sample">random sample</a>.
    The <span class="termOfArt">bias</span> of the estimator <span class="math">X</span> is the
    <a class="glossRef" href="gloss.htm#expectation">expected value</a>
    of <span class="math">(X&minus;t)</span>, the expected
    difference between the estimator and the parameter it is intended to estimate.
    If the bias of an estimator is zero, the estimator is <span class="termOfArt">unbiased</span>;
    otherwise, it is <span class="termOfArt">biased</span>.
    The bias of an estimator is the long-run average amount by which it
    differs from the parameter in repeated sampling.
    Any estimator can be written as the sum of three terms:
    the parameter it is intended to estimate, the bias of the estimator,
    and a <a class="glossRef" href="gloss.htm#chance_variability">chance error</a> that has expected value zero.
    The square-root of the expected value of the square of the chance error
    is the <a class="glossRef" href="gloss.htm#se">SE</a> of the estimator.
    The SE measures the long-run scatter of the estimator in repeated sampling.
    Estimators can be compared using summaries of their expected error.
    One common summary of the error of estimators is the
    <a class="glossRef" href="gloss.htm#mse">mean squared error
    (MSE)</a>, <span class="math">E( (X&minus;t)<sup>2</sup> )</span>, the expected value of the square of the
    difference between an estimator and the parameter it is intended to estimate.
    However, there are countless other criteria for comparing estimators.
    The square-root of the MSE is the <a class="glossRef" href="gloss.htm#rmse">root mean squared error, (RMSE)</a>.
    The units of the RMSE are the same as the units of the estimator,
    so it is easier to interpret than the MSE.
    The RMSE of an estimator is equal to the square-root of the sum of
    the square of the bias of the estimator and the square of the SE of the estimator.
    The RMSE of an unbiased estimator is its SE.
</p>

<p>
    The sample mean for random sampling with or without replacement is an unbiased
    estimator of the population mean.
    Consequently, the sample percentage <span class="math">&phi;</span> for random sampling with or
    without replacement is an unbiased estimator of the population percentage.
    The SE of the sample mean of a simple random sample of size <span class="math">n</span> from a box
    of <span class="math">N</span> tickets labeled with numbers is
    <span class="math">f&times;SD(box)/n<sup>&frac12;</sup></span>, where
    <span class="math">f=(N&minus;n)<sup>&frac12;</sup>/(N&minus;1)<sup>&frac12;</sup></span>
    is the <a class="glossRef" href="gloss.htm#fpc">finite population correction</a> and SD(box)
    is the <a class="glossRef" href="gloss.htm#sd">SD</a> of the population of numbers on the tickets in the box.
    For random sampling with replacement, the SE of the sample mean
    is <span class="math">SD(box)/n<sup>&frac12;</sup></span>.
    Because the SD of a <a class="glossRef" href="gloss.htm#0_1_box">0-1 box</a>
    is <span class="math">(p(1&minus;p))<sup>&frac12;</sup></span>, where
    <span class="math">p</span> is the fraction of tickets in the box labeled &quot;1,&quot; the SE of the
    sample percentage <span class="math">&phi;</span> of a simple random sample of size
    <span class="math">n</span> from a box
    of <span class="math">N</span> tickets labeled with numbers is
</p>

<p class="math">
    SE(&phi;) =
    f&times;(p(1&minus;p))<sup>&frac12;</sup>/n<sup>&frac12;</sup>.
</p>

<p>
    For random sampling with replacement,
</p>

<p class="math">
    SE(&phi;)=(p(1&minus;p))<sup>&frac12;</sup>/n<sup>&frac12;</sup>.
</p>

<p>
    It is rare that SD(box) is known in a situation where one desires
    to estimate the population mean or population percentage, so these
    formulae are not directly useful.
    However, there are ways to estimate SD(box).
    For any 0-1 box, SD(box)&le;50%, which gives convenient upper bounds on
    SE(<span class="math">&phi;</span>): For
    <a class="glossRef" href="gloss.htm#simple_random_sample">simple random sampling</a>,
    <span class="math">SE(&phi;)&le;f&times;50%/n<sup>&frac12;</sup></span>,
    and for <a class="glossRef" href="gloss.htm#random_sample">random sampling with replacement</a>,
    <span class="math">SE(&phi;)&le;50%/n<sup>&frac12;</sup></span>.
    These upper bounds can be quite pessimistic.
    There is no upper bound on the SD of an arbitrary list of numbers,
    and thus no upper bound on the SE of the sample mean of random draws from an arbitrary box.
    However, SD(box) can be estimated from the sample if the sample size is large.
    The <span class="termOfArt">bootstrap estimate</span> of SD(box) is
    <span class="math">s<sup>*</sup></span>, the SD of the sample.
    For 0-1 boxes, the SD of the sample is
    <span class="math">s<sup>*</sup>=(&phi;(1&minus;&phi;))<sup>&frac12;</sup></span>, where
    <span class="math">&phi;</span> is the sample percentage.
    When the sample size is large, <span class="math">s<sup>*</sup></span> tends to be an accurate
    estimate of SD(box), and the corresponding estimate of the SE of the sample mean,
    <span class="math">f&times;s<sup>*</sup>/n<sup>&frac12;</sup></span>
    (for simple random sampling) or
    <span class="math">s<sup>*</sup>/n<sup>&frac12;</sup></span> (for random sampling with replacement)
    tends to be accurate.
    The <span class="termOfArt">sample standard deviation</span>
    <span class="math">s=s<sup>*</sup>&times;(n/(n&minus;1))<sup>&frac12;</sup></span>
    is a bit larger than the SD of the sample.
    When the sample size <span class="math">n</span> is large, <span class="math">s</span> and
    <span class="math">s<sup>*</sup></span>
    are almost equal.
    For random sampling with replacement, <span class="math">s<sup>2</sup></span>
    is an unbiased estimate of the square
    of the SD of the list of numbers in the box.
    (The square of the SD of the list is called the <span class="termOfArt">variance</span> of the list.)
    It is more common to use the bootstrap estimate <span class="math">s<sup>*</sup></span> of SD(box) for estimating
    the SE of the sample percentage and to use the sample standard deviation
    <span class="math">s</span> to estimate SD(box) for estimating the SE of the sample mean.
    These formulae apply only for simple random samples and random samples with
    replacement, not for other probability samples or non-probability samples.
</p>

<h2><a id="keyTerms"></a>
    Key Terms
</h2>

<ul>
  <li>0-1 box                        </li>
  <li>average                        </li>
  <li>bias                           </li>
  <li>bootstrap estimate             </li>
  <li>chance variability             </li>
  <li>deviation                      </li>
  <li>estimator                      </li>
  <li>expected value                 </li>
  <li>finite population correction   </li>
  <li>frame                          </li>
  <li>histogram                      </li>
  <li>hypergeometric distribution    </li>
  <li>independent                    </li>
  <li>margin of error                </li>
  <li>mean                           </li>
  <li>mean squared error (MSE)       </li>
  <li>monotonic                      </li>
  <li>parameter                      </li>
  <li>population                     </li>
  <li>population mean                </li>
  <li>population percentage          </li>
  <li>population variance            </li>
  <li>random sampling                </li>
  <li>random variable                </li>
  <li>rms                            </li>
  <li>root mean squared error (RMSE) </li>
  <li>sample mean                    </li>
  <li>sample percentage              </li>
  <li>sample size                    </li>
  <li>sample standard deviation      </li>
  <li>sample variance                </li>
  <li>sampling error                 </li>
  <li>simple random sample           </li>
  <li>standard deviation SD)         </li>
  <li>standard error (SE)            </li>
  <li>statistic                      </li>
  <li>unbiased                       </li>
  <li>unit                           </li>
  <li>variance                       </li>
</ul>

</form>

<script language="JavaScript1.8" type="text/javascript"><!--
    writeChapterFooter();
// -->
</script>

</body>
</html>
